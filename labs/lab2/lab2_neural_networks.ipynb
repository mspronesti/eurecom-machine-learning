{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Fc-cAAWOp4k"
   },
   "source": [
    "# MALIS Lab Session 2 - Fall 2021\n",
    "## Due Date: Dec 3 23h59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyM-uj_BOp4m"
   },
   "source": [
    "**Group :** pronestiblias\n",
    "\n",
    "**Federico TIBLIAS, Massimiliano PRONESTI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_AQtwDCKOp4n"
   },
   "source": [
    "The aim of this lab is to practice with Neural Networks (Multi-Layer Perceptrons) via simple classification experiments and the implementation of the feedforward and backpropagation procedures.\n",
    "\n",
    "#### Learning goals\n",
    "After this lab, you should be able to:\n",
    "1. Be familiar with the elements required to define the architecture of a neural network (NN).\n",
    "2. Understand the two procedures needed to train a neural network: feedforward and backpropagation\n",
    "3. Understand the role of the learning rate and the number of iterations in the training process of a NN and how it these can affect performance.\n",
    "\n",
    "#### Instructions:\n",
    "Experiments should be made by groups of two students. Each group should produce a Jupyter Notebook with all their results and comments. We strongly encourage the addition of plots and visual representation to the report, bearing in mind that comments on the graphical data are still necessary. Code for adding images to your notebook: ```<img src=\"path/to/image.png\" />```. <Plateforme soumission des notebooks>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZKs_0AtOp4o"
   },
   "source": [
    "<h2>Introduction</h2>\n",
    "There are three parts to this lab session. \n",
    "\n",
    "1. A \"theoretical\" part: Given a set of training examples you have to decide on the architecture of the feed-forward neural network such as; number of layers, number of neuron per layers and finally the values of the weights. \n",
    "\n",
    "2. A \"programming\" part: Given the skeleton of the Python code of an MLP simulator, implement the missing functions (feedforward and backpropagation procedures). \n",
    "\n",
    "3. An \"experimental\" part: Having completed the implementation of the MLP simulator, the final step consist on training the network and testing it.\n",
    "\n",
    "<h2>Part 1: Design a neural network</h2>\n",
    "The aim of this part is to get a better understanding of the basics of Neural Networks construction. A number of sample points on a 128 by 128 grid have been assigned one out of three colors (red, green or blue). You should build a Neural Network with two inputs and three outputs which provides the exact coloring for these points. The problem can be visualized in the following figure: \n",
    "\n",
    "<img src=\"data_set.jpg\" />\n",
    "\n",
    "The file set30.x1x2rgb (in .\\data\\) contains the data corresponding to the problem defined above. The visual representation of the problem (above figure) is stored in data_set.jpg.\n",
    "\n",
    "The problem:\n",
    "\n",
    "Pairs of x1 and x2 coordinates (both ranging between 0 and 127) are associated with a specific color: \n",
    "\n",
    "* Red: output 1 0 0, \n",
    "* Green: output 0 1 0, \n",
    "* Blue: output 0 0 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** How many linear separations would be needed to perfectly separate the data points? Using the visual representation, give some appropriate equations of such linear separations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :** Two Hyperplanes are needed: <br>\n",
    "-4 * x1 + 3 * x2 + 120 = 0 <br>\n",
    "2 * x1 + 3 * x2 - 240 = 0 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the network is to correctly determine for any given (x1, x2) coordinate pair the corresponding color. \n",
    "Using the equations you proposed before, along with your lectures knowledge, your task is to <b>manually define a Neural Network which performs this task perfectly</b>. There is no need for programming or iterative training. The transfer function is assumed to be the step function: \n",
    "\n",
    "$f(t) = (t > 0)$ (it is equal to 1 if t is positive, 0 otherwise). \n",
    "\n",
    "Of course, it is your task to define the number of layers, the number of neurons per layer, and the exact values for the weights. \n",
    "\n",
    "<i>Hint: We may remember the XOR problem and how it was solved. Think also how many lines you need to create areas with only elements of that color and if the color is below or above that color.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kkmqn1bnOp4p"
   },
   "source": [
    "### Your answer :\n",
    "\n",
    "( *Fill in the correct data and fill the respective weigths and biases* )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "raw",
    "id": "rMV9r4dROp4p"
   },
   "source": [
    "Input layer:  2 units,  x1   x2\n",
    "\n",
    "First hidden layer:\n",
    "    n1 neurons:\n",
    "    \"Above or below the first plane\"\n",
    "    neuron 1: w11 = -4 <- weight from input x1 to neuron 1\n",
    "              w12 = 3 <- weight from input x2 to neuron 1\n",
    "              b1  = 90 <- bias of neuron 1 of the first hidden layer\n",
    "    \"Above or below the second plane\"\n",
    "    neuron 2: w21 = 2\n",
    "              w22 = 3\n",
    "              b2  = -240\n",
    "\n",
    "output layer:\n",
    "    n_out neurons:\n",
    "    \"R\"\n",
    "    neuron 1: w11 = 0\n",
    "              w12 = -1\n",
    "              b1  = 1\n",
    "    \"G\"\n",
    "    neuron 2: w21 = 1\n",
    "              w22 = 1\n",
    "              b2  = -1\n",
    "    \"B\"\n",
    "    neuron 3: w21 = -1\n",
    "              w22 = 1\n",
    "              b2  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cy0DpBiOp4q"
   },
   "source": [
    "#### Test with the data\n",
    "Test with the data in ./data/set30.x1x2rgb, complete the code below with your values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "print_solutions=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "dKoW4efyOp4r",
    "outputId": "a98ab8c3-5587-4464-ec7a-f6455a1797a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "rgb_df=pd.read_csv('colors.csv')\n",
    "\n",
    "x=np.array(rgb_df[['x1','x2']].copy())\n",
    "y=np.array(rgb_df[['y1','y2','y3']].copy())\n",
    "\n",
    "######################### YOUR VALUES HERE ####################\n",
    "\n",
    "# weight input -> 1st hidden layer\n",
    "W_1 =np.array([[-4,3], # to n1 of first hidden layer\n",
    "      [2,3] # to n2 of first hidden layer\n",
    "      ])\n",
    "# bias 1st hidden layer\n",
    "b_1 = np.array([90,-240]).T\n",
    "\n",
    "# nth hidden layer -> output layer\n",
    "W_out =np.array([[0,-1], # to n1 of first hidden layer\n",
    "      [1,1], # to n2 of first hidden layer\n",
    "      [-1,1]])\n",
    "b_out = np.array([1,-1,0]).T\n",
    "\n",
    "\n",
    "x1 = (b_1 + x @ W_1.T)>0 # @ is the matrix product\n",
    "\n",
    "y_hat = (b_out + x1 @ W_out.T)>0\n",
    "######################### END YOUR VALUES ######################\n",
    "# You should get 100 %\n",
    "print('accuracy : ' , 100*np.sum(y_hat==y)/(3*len(y)),'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "3bjVtxx6Op4w",
    "outputId": "686a0d8f-9960-4063-df83-1cdac632d6a7"
   },
   "outputs": [],
   "source": [
    "# do NOT modify this cell\n",
    "if print_solutions==True :\n",
    "    %load ./solutions/part1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FptDCtcaOp40"
   },
   "source": [
    "## Part 2: Implementation of a Neural Network / Multi-Layer Perceptrons\n",
    "\n",
    "In order to implement a neural network, firstly we have to implement the basic blocks, then combine them.\n",
    "\n",
    "1. **Initialization of parameters**\n",
    "    1. need as parameters the number of neurons in input, hidden layer1, hidden layer2, ..., output\n",
    "    2. random initialization of the parameters\n",
    "2. **Activation functions**\n",
    "    1. define the function sigmoid and sigmoid_derivative\n",
    "2. **Forward function**\n",
    "    1. using inputs, weights, activation functions compute y_hat\n",
    "3. **Loss function**\n",
    "    1. given as input the true y and y_hat, compute the loss\n",
    "4. **Accuracy**\n",
    "    1. given as input the true y and y_hat, compute the accuracy\n",
    "5. **Backward function**\n",
    "    1. gradient computations from last layer to first layer\n",
    "    2. update of parameters (weights,...)\n",
    "6. **Training**\n",
    "    1. needs as parameters the inputs and corresponding outputs,the learning rate, the number of epochs and the parameter verbose\n",
    "    2. repeat for the number of epochs:\n",
    "        1. shuffle the inputs\n",
    "        2. for each input : forward, loss, backward\n",
    "        3. loss and save it and if verbose==True print it\n",
    "        4. accuracy and save it and if verbose==True print it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give a look to the file **NeuralNetwork.py** and then return to the notebook to implement the missing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import logistic\n",
    "# from the file NeuralNetwork.py we import the Multi-Layer Perceptron\n",
    "from NeuralNetwork import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Activation functions**\n",
    "\n",
    "In MLP there is the function sigmoid. Using MPL.sigmoid(), implement its derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_sigmoid(a) :\n",
    "    '''\n",
    "    Derivative of sigmoid activation function. It can work with single inputs or vectors or matrices.\n",
    "    Return the sigmoid derivative of a\n",
    "    '''\n",
    "    ################# YOUR CODE HERE ####################\n",
    "    return MLP.sigmoid(a)*(1-MLP.sigmoid(a))\n",
    "    ################ END OF YOUR CODE HERE ##############\n",
    "    \n",
    "MLP.d_sigmoid=d_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do NOT modify this cell\n",
    "if print_solutions==True :\n",
    "    %load ./solutions/d_sigmoid.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feedforward function**\n",
    "\n",
    "Write a function which performs the forward operation from input to output layer. Remember you have len(self.layers) number of layers and each layer has its own parameters:\n",
    "1. self.layer[0].W are the weights between input and 1st hidden layer\n",
    "2. self.layer[0].b are the biases of the 1st hidden layer\n",
    "3. ...\n",
    "\n",
    "Each layer has as activation function the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x) :\n",
    "    '''\n",
    "    Forward function. From input layer to output layer. Input can handle 1D or 2D inputs.\n",
    "\n",
    "    INPUTS:\n",
    "    - x : numpy array of size NxD, where N is the number of samples, D is the number of input dimensions referred as n_input before\n",
    "\n",
    "    OUTPUTS:\n",
    "    - y_hat : numpy array of size NxC, where C is the number of classes\n",
    "    '''\n",
    "    ################# YOUR CODE HERE ####################\n",
    "    if(x.ndim==1):\n",
    "        x_prev = x.reshape([len(x),1])\n",
    "    else:\n",
    "        x_prev = x.T\n",
    "\n",
    "    for i in range(0,len(self.layer)) :\n",
    "        #print(self.layer[i].W.shape,x_prev.shape , self.layer[i].b.T.shape)\n",
    "        self.layer[i].a = (self.layer[i].W @ x_prev + self.layer[i].b.T)\n",
    "        #print('Activation shape',self.layer[i].a.shape )\n",
    "        self.layer[i].z = MLP.sigmoid(self.layer[i].a)\n",
    "        x_prev = self.layer[i].z\n",
    "    y_hat = x_prev.T\n",
    "    ################ END OF YOUR CODE HERE ##############\n",
    "    return y_hat\n",
    "\n",
    "MLP.forward=forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do NOT modify this cell\n",
    "if print_solutions==True :\n",
    "    %load ./solutions/forward.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Loss function**\n",
    "\n",
    "Compute the mean square loss between y_hat and y\n",
    "$$L = \\frac{1}{N}\\sum_{n=0}^{N-1} \\left(\\frac{1}{2} \\sum_{k=0}^{C-1} (\\hat{y}_{k,n} - y_{k,n})^2\\right)$$\n",
    "with $k$ be the class, and $n$ the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_hat, y) :\n",
    "    '''\n",
    "    Compute the loss between y_hat and y! they can be 1D or 2D arrays!\n",
    "\n",
    "    INPUTS:\n",
    "    - y_hat : numpy array of size NxC, N number of samples, C number of classes. It contains the estimated values of y\n",
    "    - y : numpy array of size NxC with one 1 in each row, corresponding to the correct class for that sample\n",
    "\n",
    "    OUTPUTS:\n",
    "    - L : MSE loss\n",
    "    '''\n",
    "    ################# YOUR CODE HERE ####################\n",
    "    y_diff = y_hat-y\n",
    "    L = np.sum(y_diff.T @ y_diff)/(2*len(y))\n",
    "    ################ END OF YOUR CODE HERE ##############\n",
    "\n",
    "    return L\n",
    "\n",
    "MLP.loss=loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do NOT modify this cell\n",
    "if print_solutions==True :\n",
    "    %load ./solutions/loss.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Accuracy**\n",
    "\n",
    "Compute the accuracy counting how many y_hat are equal to y over the total number of N samples. Remember the accuracy is a value in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y) :\n",
    "    '''\n",
    "    Compute the accuracy between y_hat and y\n",
    "\n",
    "    INPUTS:\n",
    "    - y_hat : numpy array of size NxC, C number of classes. It contains the estimated values of y\n",
    "    - y : numpy array of size NxC with correct values of y\n",
    "\n",
    "    OUTPUTS:\n",
    "    - acc : the accuracy value between 0 and 1\n",
    "    '''\n",
    "    ################# YOUR CODE HERE ####################\n",
    "    y_bin = np.zeros_like(y_hat)\n",
    "    y_bin[np.arange(len(y_hat)), y_hat.argmax(1)] = 1\n",
    "    y_bin[y_bin!=y] = 0\n",
    "    num_corr = np.sum(y_bin)\n",
    "    acc = num_corr / len(y)\n",
    "    ################ END OF YOUR CODE HERE ##############\n",
    "    return acc\n",
    "\n",
    "MLP.accuracy=accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do NOT modify this cell\n",
    "if print_solutions==True :\n",
    "    %load ./solutions/accuracy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Backpropagation**\n",
    "\n",
    "You can perform it in 2 ways. The first neuron by neuron as done during the lecture, or you can use matrices as explained here. The result are equivalent. A full matrix derivation can be found here http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial z^L}=\\frac{\\partial L}{\\partial \\hat{y}}=\\delta_L=\\hat{y}-y=z^L-y$$\n",
    "\n",
    "**Important** : $\\hat{y}$ and $y$ are row vectors 1$\\times$C, with C the number of classes, while $a$, $z$ and $b$ are row vectors too in this notation. So are the derivatives w.r.t. them. $W^l$ is instead a matrix $n^l \\times n^{l-1}$, where $n^l$ is the number of neurons at layer $l$, while  $n^{l-1}$ is the number of neurons at layer $l-1$\n",
    "\n",
    "**Generic layer $l$**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial z^l}=\\delta_l=\\frac{\\partial L}{\\partial a^{l+1}}\\ W^{l+1}$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a^l}=\\delta_l \\odot \\sigma'(a^l)$$\n",
    "\n",
    "$\\odot$ is the Hadamard product or elementwise multiplication\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b^l}=\\frac{\\partial L}{\\partial a^l}$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W^l}=\\left(\\frac{\\partial L}{\\partial a^l}\\right)^T\\ (z^{l-1})$$\n",
    "\n",
    "with $z^{-1}$, the z at layer -1 is $x$ the input vector of size 1$\\times$D, where D is the number of features\n",
    "\n",
    "After all computations, remember to compute the update of the gradients using the learning rate $\\eta$\n",
    "\n",
    "$$W^l_{new}=W^l-\\eta \\frac{\\partial L}{\\partial W^l}$$\n",
    "\n",
    "$$b^l_{new}=b^l-\\eta \\frac{\\partial L}{\\partial b^l}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(self,x,y,y_hat,learning_rate) :\n",
    "    '''\n",
    "    Backpropagate the error from last layer to input layer and then update the parameters\n",
    "\n",
    "    INPUTS:\n",
    "    - y_hat : numpy array of size NxC, C number of classes. It contains the estimated values of y\n",
    "    -y : numpy array of size NxC with correct values of y\n",
    "\n",
    "    OUTPUTS: (compute the error at the different levels and for each layer)\n",
    "    - d_a\n",
    "    - d_z\n",
    "    - delta_L\n",
    "    - delta_l\n",
    "    - d_W\n",
    "    - d_b\n",
    "    '''\n",
    "# compute gradients\n",
    "\n",
    "    ################# YOUR CODE HERE ####################\n",
    "    L = len(self.layer)-1\n",
    "    #print('dzL:',y_hat.shape,y.shape)\n",
    "    self.layer[L].d_z = (y_hat-y)\n",
    "    #print('daL:',self.layer[L].d_z.shape,d_sigmoid(self.layer[L].a).T.shape)\n",
    "    self.layer[L].d_a = self.layer[L].d_z * d_sigmoid(self.layer[L].a).T\n",
    "    #print('dWL:',self.layer[L].d_a.T.shape,self.layer[L-1].z.T.shape)\n",
    "    self.layer[L].d_W = self.layer[L].d_a.T @ self.layer[L-1].z.T\n",
    "    #print('dbL:',self.layer[L].d_a.T.shape)\n",
    "    self.layer[L].d_b = self.layer[L].d_a\n",
    "    for i in range(len(self.layer)-2,1,-1):\n",
    "        #print('dzi:',self.layer[i+1].d_a.shape,self.layer[i+1].W.shape)\n",
    "        self.layer[i].d_z = self.layer[i+1].d_a @ self.layer[i+1].W\n",
    "\n",
    "        #print('dai:',self.layer[i].d_z.shape,d_sigmoid(self.layer[i].a).T.shape)\n",
    "        self.layer[i].d_a = self.layer[i].d_z * d_sigmoid(self.layer[i].a).T\n",
    "\n",
    "        #print('dWi:',self.layer[i].d_a.T.shape,self.layer[i-1].z.shape)\n",
    "        self.layer[i].d_W = self.layer[i].d_a.T @ self.layer[i-1].z.T\n",
    "\n",
    "        #print('dbi:',self.layer[i].d_a.shape)\n",
    "        self.layer[i].d_b = self.layer[i].d_a\n",
    "    self.layer[0].d_z = self.layer[1].d_a @ self.layer[1].W\n",
    "    self.layer[0].d_a = self.layer[0].d_z * d_sigmoid(self.layer[0].a).T\n",
    "    self.layer[0].d_W = self.layer[0].d_a.T @ x\n",
    "    self.layer[0].d_b = self.layer[0].d_a\n",
    "    ################ END OF YOUR CODE HERE ##############\n",
    "\n",
    "# apply gradients\n",
    "    # just one for loop passing through all layers is sufficient\n",
    "    # apply the gradients only to self.layer[i].b and self.layer[i].W\n",
    "\n",
    "    ################# YOUR CODE HERE ####################\n",
    "    for i in range(len(self.layer)):\n",
    "        self.layer[i].W -= learning_rate * self.layer[i].d_W\n",
    "        self.layer[i].b -= learning_rate * self.layer[i].d_b\n",
    "    ################ END OF YOUR CODE HERE ##############\n",
    "    \n",
    "MLP.backpropagation=backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOTD_KvkOp41"
   },
   "outputs": [],
   "source": [
    "# do NOT modify this cell\n",
    "if print_solutions==True :\n",
    "    %load ./solutions/backpropagation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Training and Recall experiments</h2>\n",
    "\n",
    "Train the network using the iris dataset (https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "* 4 features for every input\n",
    "* 3 possible labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EsfSDYUpWRs"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "shuffle=np.random.permutation(range(len(iris.data)))\n",
    "X = np.array(iris.data)[shuffle,:]\n",
    "y = np.eye(3)[iris.target,:]\n",
    "y=y[shuffle,:]\n",
    "\n",
    "x_train=X[0:120,:]\n",
    "y_train=y[0:120,:]\n",
    "x_test=X[120:,:]\n",
    "y_test=y[120:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "[0.3416666666666667]\n",
      "Epoch 0 : loss = 9.73722e-05, accuracy = 34.17 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667]\n",
      "Epoch 10 : loss = 1.14673e-02, accuracy = 71.67 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875]\n",
      "Epoch 20 : loss = 3.52289e-03, accuracy = 87.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334]\n",
      "Epoch 30 : loss = 1.12702e-03, accuracy = 95.83 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333]\n",
      "Epoch 40 : loss = 5.39887e-04, accuracy = 93.33 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975]\n",
      "Epoch 50 : loss = 1.85242e-04, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333]\n",
      "Epoch 60 : loss = 3.54693e-04, accuracy = 80.83 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334]\n",
      "Epoch 70 : loss = 1.91531e-04, accuracy = 95.83 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667]\n",
      "Epoch 80 : loss = 2.31632e-04, accuracy = 94.17 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975]\n",
      "Epoch 90 : loss = 8.48455e-05, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0]\n",
      "Epoch 100 : loss = 1.64187e-04, accuracy = 100.00 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975]\n",
      "Epoch 110 : loss = 7.58661e-05, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975]\n",
      "Epoch 120 : loss = 6.72213e-05, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667]\n",
      "Epoch 130 : loss = 3.89427e-05, accuracy = 96.67 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.95, 0.975, 0.9833333333333333, 0.975]\n",
      "Epoch 140 : loss = 4.02920e-05, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.95, 0.975, 0.9833333333333333, 0.975, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 1.0, 0.95, 0.9416666666666667, 0.975, 0.9583333333333334]\n",
      "Epoch 150 : loss = 8.85930e-05, accuracy = 95.83 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.95, 0.975, 0.9833333333333333, 0.975, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 1.0, 0.95, 0.9416666666666667, 0.975, 0.9583333333333334, 0.9583333333333334, 0.9666666666666667, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333]\n",
      "Epoch 160 : loss = 4.77867e-05, accuracy = 98.33 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.95, 0.975, 0.9833333333333333, 0.975, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 1.0, 0.95, 0.9416666666666667, 0.975, 0.9583333333333334, 0.9583333333333334, 0.9666666666666667, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9916666666666667, 0.9666666666666667, 0.9916666666666667, 0.975, 0.975, 0.975, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.975]\n",
      "Epoch 170 : loss = 4.65726e-05, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.95, 0.975, 0.9833333333333333, 0.975, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 1.0, 0.95, 0.9416666666666667, 0.975, 0.9583333333333334, 0.9583333333333334, 0.9666666666666667, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9916666666666667, 0.9666666666666667, 0.9916666666666667, 0.975, 0.975, 0.975, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9583333333333334, 0.975, 0.9833333333333333, 0.9583333333333334, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.95, 0.975]\n",
      "Epoch 180 : loss = 3.64125e-05, accuracy = 97.50 %\n",
      "[0.3416666666666667, 0.9666666666666667, 0.6583333333333333, 0.7, 0.925, 0.7333333333333333, 0.9333333333333333, 0.7166666666666667, 0.9833333333333333, 0.9583333333333334, 0.7166666666666667, 0.9666666666666667, 0.8583333333333333, 0.9, 0.9333333333333333, 0.9416666666666667, 0.9333333333333333, 0.9333333333333333, 0.9583333333333334, 0.9583333333333334, 0.875, 0.925, 0.7666666666666667, 0.9333333333333333, 0.975, 1.0, 0.975, 0.9583333333333334, 0.9583333333333334, 0.8833333333333333, 0.9583333333333334, 0.8916666666666667, 0.975, 0.9583333333333334, 0.9916666666666667, 0.95, 0.9666666666666667, 0.9833333333333333, 0.9916666666666667, 0.9833333333333333, 0.9333333333333333, 1.0, 0.975, 0.975, 1.0, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9583333333333334, 0.975, 0.8833333333333333, 0.9583333333333334, 1.0, 1.0, 0.9666666666666667, 0.9833333333333333, 0.975, 0.925, 0.9833333333333333, 0.8083333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9666666666666667, 0.975, 0.9833333333333333, 0.975, 0.9583333333333334, 0.9833333333333333, 0.9583333333333334, 0.9416666666666667, 0.9583333333333334, 1.0, 1.0, 0.95, 0.9583333333333334, 0.9833333333333333, 0.9416666666666667, 0.9666666666666667, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9333333333333333, 0.975, 0.975, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.8666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.975, 1.0, 1.0, 0.9333333333333333, 0.9916666666666667, 0.9833333333333333, 0.9416666666666667, 0.9166666666666666, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.975, 1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.9333333333333333, 0.9833333333333333, 0.975, 0.9416666666666667, 0.975, 0.975, 0.9833333333333333, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 0.9666666666666667, 0.95, 0.975, 0.9833333333333333, 0.975, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.9833333333333333, 1.0, 0.95, 0.9416666666666667, 0.975, 0.9583333333333334, 0.9583333333333334, 0.9666666666666667, 0.975, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.9916666666666667, 0.9833333333333333, 0.9833333333333333, 0.9916666666666667, 0.9666666666666667, 0.9916666666666667, 0.975, 0.975, 0.975, 0.9833333333333333, 0.9833333333333333, 0.9666666666666667, 0.975, 0.9583333333333334, 0.975, 0.9833333333333333, 0.9583333333333334, 0.9833333333333333, 0.9833333333333333, 0.975, 0.975, 0.95, 0.975, 0.975, 0.9666666666666667, 0.9666666666666667, 0.975, 1.0, 0.9666666666666667, 0.9833333333333333, 0.9583333333333334, 1.0, 0.9916666666666667]\n",
      "Epoch 190 : loss = 2.79489e-05, accuracy = 99.17 %\n",
      "final : loss = 4.058e-05 , accuracy = 96.67 %\n",
      "\n",
      "TEST\n",
      "loss = 8.062e-05 , accuracy = 93.33 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neural Network (NN) parameters\n",
    "epochs=200\n",
    "learning_rate=0.2\n",
    "verbose=True\n",
    "print_every_k=10\n",
    "\n",
    "# Initialization of the NN\n",
    "NN1 = MLP([4, 10, 3])\n",
    "print('TRAINING')\n",
    "# Training\n",
    "NN1.training(x_train,y_train,learning_rate,epochs,verbose,print_every_k)\n",
    "# Compute the training loss and accuracy after having completer the training\n",
    "y_hat=NN1.forward(x_train)\n",
    "print('final : loss = %.3e , accuracy = %.2f %%'%(MLP.loss(y_hat,y_train),100*MLP.accuracy(y_hat,y_train)))\n",
    "\n",
    "# Test\n",
    "print('\\nTEST')\n",
    "y_hat=NN1.forward(x_test)\n",
    "print('loss = %.3e , accuracy = %.2f %%\\n'%(MLP.loss(y_hat,y_test),100*MLP.accuracy(y_hat,y_test)))\n",
    "\n",
    "plt.plot(list(range(epochs)),NN1.losses,c='r',marker='o',ls='--');\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss value\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(epochs)),NN1.accuracies,c='g',marker='o',ls='--');\n",
    "plt.title(\"Training accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous cell as example, try to change the parameters in order to obtain a training accuracy above 99% and a test accuracy above 95%.\n",
    "\n",
    "**Explain** the difference between the new parameters and the old ones. What was missing in the old ones?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": 608,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Learning rate and epochs were too low to reach convergence. Giving the model more time to adjust and increasing the backpropagation steps raises the accuracy over the desired levels."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab2_neural_networks.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "pycharm-d2c9f13c",
   "language": "python",
   "display_name": "PyCharm (eurecom-malis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}